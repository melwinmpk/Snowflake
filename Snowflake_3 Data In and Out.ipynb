{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "666b80ae",
   "metadata": {},
   "source": [
    "<h2>Snowflake suppors data loading in 2 Primary Ways</h2>\n",
    "<ul>\n",
    "    <li>Copy Command</li>\n",
    "    <li>Snowpipe</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cb0e2b",
   "metadata": {},
   "source": [
    "<h3>Copy Command</h3>\n",
    "<ul>\n",
    "<li>The copy command requires the usage of a virtual warehouse.</li>\n",
    "<li>When new data is loaded into a table, one or more new micro partitions are written to the storage,</li>\n",
    "<li>and every time a new micro partition for a table is written, the table's metadata is changed.</li>\n",
    "<li>This metadata contains information on the micro partitions, the range of values for each columns and other optimization information.</li>\n",
    "<li>At the same time, extra metadata about the file that has been imported into the database is stored</li>\n",
    "<li>in the metadata database.</li>\n",
    "<li>And all of this metadata is stored in Snowflake's cloud services layer.</li>\n",
    "\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dcb4a0",
   "metadata": {},
   "source": [
    "<h3>Snowpipe</h3>\n",
    "<ul>\n",
    "<li>So Snowpipe is the ideal technique for loading data when the data is arriving continuously in a messaging or a streaming manner.</li>\n",
    "<li>So regardless of how the data is loaded into Snowflake, new micro partitions are created and metadata updates are performed.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8d571d",
   "metadata": {},
   "source": [
    "<h3>Before data can be processed into a snowflake table, it must first be made available in a snowflake stage.</h3>\n",
    "<ul>\n",
    "    <li>Stages in snowflake help snowflake load and unload data easily.Similar to how data warehouse is used.</li>\n",
    "    <li>Staging Snowflake uses a stage object.</li>\n",
    "    <li>Snowflake uses stages to aid in the loading and unloading of data.</li>\n",
    "    <li>In order to load data into a snowflake table.</li>\n",
    "    <li>The data first must be available in a snowflake stage.</li>\n",
    "    <li>Copy command then can be used to load data into a table after it was made available in a stage.</li>\n",
    "    <li>Similarly, data unloading or exporting is also performed via stages.</li>\n",
    "<!--     <li>This allows snowflake access to the data so that it can be loaded into a table.</li>\n",
    "    <li>Once the data is available in a stage, the copy command can then be used to copy the data into a database table.</li> -->\n",
    "</ul>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64416b06",
   "metadata": {},
   "source": [
    "<h2>Types of Stage</h2>\n",
    "<ul>\n",
    "    <li>External Stages</li>\n",
    "    <li>Internal Stages</li>\n",
    "</ul>\n",
    "\n",
    "<h3>Internal Stages</h3>\n",
    "<ul>\n",
    "    <li>Internal stages store data in themselves.</li>\n",
    "    <li>Once data has been uploaded into an internal stage, it can then be loaded into a table using the copy command.</li>\n",
    "    <li>There are three types of internal stages, so </li>\n",
    "    <li><b>Named internal stages</b></li> \n",
    "    <ul>\n",
    "    <li>The stage objects that can be created, dropped and modified as required.</li>\n",
    "    <li>They offer a lot more flexibility than user and table stages.</li>\n",
    "    <li>They have various advantages over the user and table stages, so they allow you to customize the file format parameter.</li>\n",
    "        <li>That means you can set up a stage once and use it to load several files and several tables.</li>\n",
    "        <li>they can be assigned security and user access rights and therefore they can be shared across multiple users.</li>\n",
    "    </ul>    \n",
    "    <li><b>Table Stage</b></li>\n",
    "    <ul>\n",
    "        <li>it is automatically created for each table and can be used to load data into that table.</li>\n",
    "        <li>Files that are loaded into a table stage then can be loaded into the table associated with that stage.</li>\n",
    "        <li>Multiple users can access a table stage, but it can only load data into one table.</li>\n",
    "        <li>And that one table is the table that is associated with the stage.</li>\n",
    "        <li>Table stages do not allow you to change the file format options, so these options must be included as part of the copy command.</li>\n",
    "        <li>Table stage is also do not allow data transformations to be applied while loading data.</li>\n",
    "    </ul>    \n",
    "    <li><b>User Stage</b></li>\n",
    "    <ul>\n",
    "        <li>each user gets a personal stage as well, which is created as soon as the user is created. User stages are also a subtype of an internal stage.</li>\n",
    "        <li>Users cannot access each other's stages, so a user can access only their own stage.</li>\n",
    "        <li>They cnnot be modified</li>\n",
    "    </ul>\n",
    "    <li>Data from on premises system can be loaded into snowflake using internal stages.</li>\n",
    "    <li>So each table and user in Snowflake are assigned an internal stage by default, and it is not possible to drop or modify that stage.</li>\n",
    "    <li>A very important point that data stored in a snowflake internal stage is counted towards your snowflake account. Total storage.So it is suggested that if you have processed data through internal stages and that data has been loaded\n",
    "into tables, it is advised that the internal stages are cleared so that you can avoid unnecessary costs.</li>\n",
    "    \n",
    "</ul>    \n",
    "\n",
    "Example of Internal Stage\n",
    "\n",
    "<pre>\n",
    "# NAMED INTERNAL STAGE\n",
    "CREATE OR REPLACE STAGE LU_Airport_CSV_Stage\n",
    "FILE_FORMAT = (TYPE = csv FIELD_DELIMITER = '.' FIELD_OPTIONALLY_ENCLOSED_BY = '\"' SKIP_HEADER = 1);\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc11aee0",
   "metadata": {},
   "source": [
    "<h3>External Stages</h3>\n",
    "<ul>\n",
    "<li>External stage refers to a storage location that is outside of Snowflake example AWS S3, Azure Blob storage, Google Storage </li>\n",
    "<li>Once an external stage has been defined, the copy command then can be used to load data from that external\n",
    "stage into a snowflake table.</li>\n",
    "    <li>The stage itself does not store anything, but rather refers to the cloud storage.</li>\n",
    "    <li>Snowflake does not control the external storage cloud location.</li>\n",
    "    <li>In External stage definitions. They include information on how to connect to the cloud storage location. This information covers the path to the cloud storage credentials to securely access the cloud storage. And if the data in cloud storage has been encrypted, the key for decrypting this data and then finally the format of the file being loaded.</li>\n",
    "    <li>Snowflake does not charge for the fees associated with storing data in an external stage because an external stage refers to a cloud storage location which is outside of Snowflake's network.The fees of storing data in an external cloud storage therefore is charged by the cloud provider who\n",
    "\n",
    "actually are providing that external storage.</li>\n",
    "</ul>\n",
    "Example of a External table\n",
    "<pre>\n",
    "CREATE OR REPLACE STAGE my_first_external_stage\n",
    "url='s3://<bucket_name>/folder/subfolder'\n",
    "storage_integration = < storage_integration_name >\n",
    "file_format = (type = 'CSV' field_delimiter = ',');\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9519db4e",
   "metadata": {},
   "source": [
    "<h3>Hands on On Premesis System </h3>\n",
    "\n",
    "link=> https://ca-flight-data-for-download.s3.amazonaws.com/L_AIRPORT_ID.csv\n",
    "\n",
    "please refer \"Assignment 4 Lab Objective Load data into a table using named internal stage\" for further understanding\n",
    "<p>Loading the Data that is sotred in csv format in PC to Snowflake </p>\n",
    "\n",
    "<!-- <pre>\n",
    "\n",
    "CREATE TABLE LU_Airport(\n",
    "Airline_ID Number,\n",
    "Airline_Description String\n",
    ");\n",
    "\n",
    "# NAMED INTERNAL STAGE\n",
    "CREATE OR REPLACE STAGE LU_Airport_CSV_Stage\n",
    "FILE_FORMAT = (TYPE = csv FIELD_DELIMITER = '.' FIELD_OPTIONALLY_ENCLOSED_BY = '\"' SKIP_HEADER = 1);\n",
    "\n",
    "USE DATABASE dev_lnd;\n",
    "\n",
    "PUT 'file:///C:/snowpro/..../L_AIRPORT_ID.csv' @LU_Airport_CSV_Stage;\n",
    "\n",
    "LIST @LU_Airport_CSV_Stage;\n",
    "\n",
    "USE DATABASE dev_lnd;\n",
    "\n",
    "COPY INTO LU_Airport FROM @LU_Airport_CSV_Stage;\n",
    "\n",
    "SELECT * FROM LU_Airport;\n",
    "\n",
    "REMOVE @LU_Airport_CSV_Stage;\n",
    "\n",
    "</pre> -->\n",
    "\n",
    "<b>Is the data encrypted prior to being transferred to a Snowflake internal stage?</b><br>\n",
    "Yes. The Data is encrypted prior before being transferred to a Snowflake Internal stage <br>\n",
    "<b>Is the data in a Snowflake internal stage stored in an encrypted format?</b><br>\n",
    "Yes. By default the data that is stored in Internal stage is encrypted. (in Gzip format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a321fda8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65b0d3f4",
   "metadata": {},
   "source": [
    "<p>to connect to snowsql</p>\n",
    "<ul>\n",
    "<li>install snowsql in the PC</li>\n",
    "<li>open cmd</li>\n",
    "<li><pre>snowsql -a < accountname >.< region > -u < username ></pre>\n",
    "    example\n",
    "    <pre>snowsql -a yta07909.us-east-1 -u SFADMIN</pre>\n",
    "</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35768fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
