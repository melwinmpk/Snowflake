{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "006aafd9",
   "metadata": {},
   "source": [
    "## Snowflake Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c60fc2",
   "metadata": {},
   "source": [
    "<p>Snowflake’s architecture is a <b>hybrid of traditional shared-disk and shared-nothing database architectures</b>. Similar to shared-disk architectures, Snowflake uses a central data repository for persisted data that is accessible from all compute nodes in the platform. But similar to shared-nothing architectures, Snowflake processes queries using MPP (massively parallel processing) compute clusters where each node in the cluster stores a portion of the entire data set locally. This approach offers the data management simplicity of a shared-disk architecture, but with the performance and scale-out benefits of a shared-nothing architecture.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce76703",
   "metadata": {},
   "source": [
    "<img src='https://docs.snowflake.com/en/_images/architecture-overview.png'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1e5673",
   "metadata": {},
   "source": [
    "<b>Snowflake’s unique architecture consists of three key layers:</b>\n",
    "<ul>\n",
    "    <li>Database Storage</li>\n",
    "    <li>Query Processing</li>\n",
    "    <li>Cloud Services</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619a48f6",
   "metadata": {},
   "source": [
    "<h3>Database Storage</h3>\n",
    "<p>\n",
    "When data is loaded into Snowflake, Snowflake reorganizes that data into its internal optimized, compressed, columnar format. Snowflake stores this optimized data in cloud storage.\n",
    "</p>\n",
    "<p>\n",
    "Snowflake manages all aspects of how this data is stored — the organization, file size, structure, compression, metadata, statistics, and other aspects of data storage are handled by Snowflake. <b>The data objects stored by Snowflake are not directly visible nor accessible by customers; they are only accessible through SQL query operations run using Snowflake.</b>\n",
    "</p>\n",
    "\n",
    "<h3>Query Processing</h3>\n",
    "<p>Query execution is performed in the processing layer. Snowflake processes queries using “virtual warehouses”. Each virtual warehouse is an MPP compute cluster composed of multiple compute nodes allocated by Snowflake from a cloud provider.</p>\n",
    "<p>Each virtual warehouse is an independent compute cluster that does not share compute resources with other virtual warehouses. As a result, each virtual warehouse has no impact on the performance of other virtual warehouses.</p>\n",
    "<p>Note:Melwin Plese Note virtual warehouse have a different meaning in Snowflake its nothing but a Compute Engine\n",
    "<h3>Cloud Services</h3>\n",
    "<p>The cloud services layer is a collection of services that coordinate activities across Snowflake. These services tie together all of the different components of Snowflake in order to process user requests, from login to query dispatch. The cloud services layer also runs on compute instances provisioned by Snowflake from the cloud provider.</p>\n",
    "<p>Services managed in this layer include:</p>\n",
    "<ul>\n",
    "    <li>Authentication</li>\n",
    "    <li>Infrastructure management</li>\n",
    "    <li>Metadata management</li>\n",
    "    <li>Query parsing and optimization</li>\n",
    "    <li>Access control</li>\n",
    "</ul>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644f467c",
   "metadata": {},
   "source": [
    "<h3>Connecting to Snowflake</h3>\n",
    "<p>Snowflake supports multiple ways of connecting to the service:</p>\n",
    "<ul>\n",
    "    <li>A web-based user interface from which all aspects of managing and using Snowflake can be accessed.</li>\n",
    "    <li>Command line clients (e.g. SnowSQL) which can also access all aspects of managing and using Snowflake.</li>\n",
    "    <li>ODBC and JDBC drivers that can be used by other applications (e.g. Tableau) to connect to Snowflake.</li>\n",
    "    <li>Native connectors (e.g. Python, Spark) that can be used to develop applications for connecting to Snowflake.</li>\n",
    "    <li>Third-party connectors that can be used to connect applications such as ETL tools (e.g. Informatica) and BI tools (e.g. ThoughtSpot) to Snowflake.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1a3929",
   "metadata": {},
   "source": [
    "<h3>Micro-partitions</h3>\n",
    "<ul>\n",
    "<li>So data in Snowflake is automatically organized into partitions known as micro partitions.</li>\n",
    "<li>Micro partitions in Snowflake are managed automatically and don't require intervention by the user.</li>\n",
    "<li>As the name suggests, micro partitions are relatively small and each micro partition will generally\n",
    "contain <b>50 MB to 500 MB</b> of uncompressed data.However, do note that the actual stored data is smaller as data in Snowflake is always stored with compression.</li>\n",
    "<li>Micro partitions are added to a table in the order of how the data arrived in the table.<br>\n",
    "So if additional data is added to a table, another micro partition or possibly multiple micro partitions<br>\n",
    "depending on the size of the data, will be created to accommodate this data.Snowflake.</li>\n",
    "<li>Micro partitions are immutable, which means they cannot be changed once created.<br>\n",
    "Any update to existing data or loading of new data into a table will result in new micro partitions\n",
    "being created.<br>\n",
    "Because micro partitions are immutable and any update or new data must be added into a new micro partition.<br>\n",
    "Therefore, it is not necessary that similar partition values will always be in the same physical partition.\n",
    "</li>\n",
    "<li>Snowflake must keep track of what range of data is in which partitions so that it can use that information\n",
    "for efficient query processing.</li>\n",
    "<li>Now Snowflake maintains several different kinds of metadata for a given table for this purpose.<br>\n",
    "It stores the range of column values in its metadata.<br>\n",
    "That is the maximum and minimum value for each column in each micro partition.<br>\n",
    "With this metadata information, Snowflake can intelligently decide which partitions to read when processing a query.<br>\n",
    "Similarly, it also stores the count of distinct values for each column in the metadata and certain<br>\n",
    "other information to assist in query optimization.</li>\n",
    "<li>Now, another important aspect is that within each micro partition, the data is stored in a columnar format.<br>\n",
    "So each column is stored compressed, and snowflake automatically determines the most appropriate and\n",
    "best compression algorithm.<br>\n",
    "    Storing data in columnar format enables Snowflake to optimize queries even further when a subset of\n",
    "columns are accessed.<br>\n",
    "So consider this straightforward SQL example on the screen where we are querying the table on the left</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124b4e54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
